{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anms5519/Plant-Disease-Prediction-Using-Leaf/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TFGbXvqnO9K",
        "outputId": "350dff79-3bc1-4a2c-81e4-38091e0e1076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, typeguard, tensorflow-addons, keras-tuner\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-tuner-1.4.7 kt-legacy-1.0.5 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner tensorflow-addons shap plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JENO8vmGnWfb",
        "outputId": "c73b1ab1-f262-4a5a-c91b-9d1f8d0ecfde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "drive_base_path = '/content/drive/My Drive/PlantDiseaseProject/'\n",
        "model_path = drive_base_path + 'plant_disease_model_advanced.h5'\n",
        "organized_dataset_path = drive_base_path + 'PlantVillage_organized/'\n",
        "logs_path = drive_base_path + 'training_logs/'\n",
        "os.makedirs(organized_dataset_path, exist_ok=True)\n",
        "os.makedirs(logs_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxP3rx8lnoNr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset_path = '/content/PlantVillage-Dataset-master/raw/color'\n",
        "train_path = os.path.join(organized_dataset_path, 'train')\n",
        "val_path = os.path.join(organized_dataset_path, 'validation')\n",
        "test_path = os.path.join(organized_dataset_path, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPrmr4WfRy5C"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/spMohanty/PlantVillage-Dataset/archive/master.zip\n",
        "!unzip -q master.zip\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    os.makedirs(os.path.join(organized_dataset_path, split), exist_ok=True)\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_dir = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        images = [img for img in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, img))]\n",
        "        if len(images) == 0:\n",
        "            print(f\"{class_name} is empty, skipping...\")\n",
        "            continue\n",
        "        training, test_val_imgs = train_test_split(images, test_size=0.4, random_state=42)\n",
        "        val_imgs, test_imgs = train_test_split(test_val_imgs, test_size=0.5, random_state=42)\n",
        "        for split, split_images in zip(['train', 'validation', 'test'], [training, val_imgs, test_imgs]):\n",
        "            split_class_dir = os.path.join(organized_dataset_path, split, class_name)\n",
        "            os.makedirs(split_class_dir, exist_ok=True)\n",
        "            for img in split_images:\n",
        "                shutil.copy(os.path.join(class_dir, img), os.path.join(split_class_dir, img))\n",
        "print(\"Dataset has been organized and saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew3kxIoRn_j7",
        "outputId": "d5513784-5bc8-4f28-b1cf-5e3ca48f4172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 32571 images belonging to 38 classes.\n",
            "Found 10858 images belonging to 38 classes.\n",
            "Found 10876 images belonging to 38 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMG_SIZE = (224, 224)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.8, 1.2]  # Additional augmentation\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "test_generator = validation_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-qmUNHcoWSL",
        "outputId": "b6ac3cb0-ec6a-4135-f046-163d3556348c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pius-9JEoZDi",
        "outputId": "622345b4-7ada-48e2-bcd0-0028aedc7fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "320               |320               |units\n",
            "0.2               |0.2               |dropout\n",
            "0.001             |0.001             |learning_rate\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m 483/1018\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:22:57\u001b[0m 9s/step - accuracy: 0.1005 - loss: 3.4080"
          ]
        }
      ],
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(hp.Int('units', min_value=128, max_value=512, step=64), activation='relu'),\n",
        "        layers.Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)),\n",
        "        layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='keras_tuner_logs',\n",
        "                     project_name='plant_disease_tuning')\n",
        "tuner.search(train_generator, epochs=10, validation_data=validation_generator)\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "model.save(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXfBtD1DofUB"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = tf.reduce_mean(conv_outputs * pooled_grads, axis=-1)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "def explain_shap(model, img_array):\n",
        "    explainer = shap.GradientExplainer(model, img_array)\n",
        "    shap_values = explainer.shap_values(img_array)\n",
        "    shap.image_plot(shap_values, -img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKi-7HpvoglC"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "upload = widgets.FileUpload(accept='image/*', multiple=True, description='Upload Images:')\n",
        "confidence_slider = widgets.FloatSlider(description='Confidence Threshold:', min=0.0, max=1.0, value=0.5,\n",
        "                                        style={'description_width': 'initial'}, layout=widgets.Layout(width='500px'))\n",
        "top_n_slider = widgets.IntSlider(description='Top Predictions:', min=1, max=5, value=3,\n",
        "                                 style={'description_width': 'initial'}, layout=widgets.Layout(width='500px'))\n",
        "predict_button = widgets.Button(description='Predict', button_style='primary', layout=widgets.Layout(width='200px'))\n",
        "output = widgets.Output(layout=widgets.Layout(border='1px solid black'))\n",
        "def on_predict_button_clicked(b):\n",
        "    output.clear_output()\n",
        "    if not upload.value:\n",
        "        with output:\n",
        "            print(\"Please upload an image first.\")\n",
        "        return\n",
        "    for key in upload.value:\n",
        "        uploaded_file = upload.value[key]\n",
        "        content = uploaded_file['content']\n",
        "        img = Image.open(io.BytesIO(content))\n",
        "        img = img.resize((224, 224))\n",
        "        img_array = np.expand_dims(img, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "        preds = model.predict(img_array)\n",
        "        preds = tf.nn.softmax(preds, axis=1)\n",
        "        preds = preds.numpy()\n",
        "        display(img)\n",
        "        indices = np.argsort(preds[0])[:top_n_slider.value:][::-1]\n",
        "        top_preds = preds[0][indices]\n",
        "        top_classes = [class_names[i] for i in indices]\n",
        "        with output:\n",
        "            found = False\n",
        "            for pred, cls in zip(top_preds, top_classes):\n",
        "                if pred >= confidence_slider.value:\n",
        "                    print(f\"{cls}: {pred*100:.2f}%\")\n",
        "                    found = True\n",
        "            if not found:\n",
        "                print(\"No predictions above the confidence threshold.\")\n",
        "        print(\"Processing file:\", key)\n",
        "\n",
        "predict_button.on_click(on_predict_button_clicked)\n",
        "\n",
        "controls = widgets.VBox([upload, confidence_slider, top_n_slider, predict_button],\n",
        "                        layout=widgets.Layout(display='flex', flex_flow='column', align_items='stretch', width='500px'))\n",
        "\n",
        "display(widgets.HBox([controls, output], layout=widgets.Layout(display='flex', flex_flow='row', align_items='stretch')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhrW-TizoiyK"
      },
      "outputs": [],
      "source": [
        "!pip install flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McuOvJ6_omDh"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "app = Flask(__name__)\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    file = request.files['image']\n",
        "    img = Image.open(io.BytesIO(file.read()))\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.expand_dims(img, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    preds = model.predict(img_array)\n",
        "    preds = tf.nn.softmax(preds, axis=1)\n",
        "    preds = preds.numpy()\n",
        "    top_indices = np.argsort(preds[0])[::-1][:3]\n",
        "    top_preds = preds[0][top_indices]\n",
        "    top_classes = [class_names[i] for i in top_indices]\n",
        "    return jsonify({'predictions': [{'class': cls, 'confidence': float(pred)} for cls, pred in zip(top_classes, top_preds)]})\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt5q971NUFEVfME8AWc/1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}